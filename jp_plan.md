# 日本語版タグリスト解析スクリプト計画

## 概要

複数のファイル (`scp-jp_tag-list.txt` および `scp-jp_fragment_*.txt`) に分割されたSCP財団Wikiの日本語版タグリストを解析し、タグ情報を抽出してJSONファイル (`jp_tags.json`) を作成するPythonスクリプトの計画です。

## 処理フロー

1.  **ファイル群の読み込みと結合:**
    *   起点となる `scp-jp_tag-list.txt` を読み込みます。
    *   ファイル内容を走査し、`[[include :scp-jp:fragment:FILE_NAME]]` 構文を見つけたら、対応するフラグメントファイル (`scp-jp_fragment_FILE_NAME`) の内容を読み込み、元の位置に展開します。これを再帰的に行い、全てのファイル内容を結合した単一のテキストデータを生成します。
2.  **タグ情報抽出:** 結合されたテキストデータを行ごとに走査し、正規表現を用いて以下の情報を抽出します。
    *   **日本語タグ名:** `[[...|JP_TAG_NAME]]]` から抽出します。
    *   **英語タグ名:** `//(EN_TAG_NAME)//` から抽出します (存在する場合のみ)。
    *   **制限アイコン:** `,,ICON,,` から抽出します (存在する場合のみ)。
    *   **説明文:** `-` 以降のテキストを抽出します。
    *   **メタ情報:** `* // KEY: VALUE //` から抽出します。
3.  **データ構造化:** 抽出した情報をタグごとにPythonの辞書オブジェクトとしてまとめます。英語タグ名と制限アイコンはオプション情報として扱います。
    ```python
    {
        "name_jp": "日本語タグ名",
        "name_en": "英語タグ名" or None,
        "description": "説明文",
        "icon": "制限アイコン" or None,
        "meta": { # メタ情報
            "key1": ["value1", "value2"],
            ...
        }
    }
    ```
4.  **JSON出力:** 構造化されたタグデータのリストをJSONファイル (`jp_tags.json`) に書き出します。

## 処理フロー図 (Mermaid)

```mermaid
graph TD
    A[開始] --> B{ファイルリスト定義\n(scp-jp_tag-list.txt, scp-jp_fragment_*.txt)};
    B --> C{全ファイル内容読み込み};
    C --> D{Include展開処理\n(再帰的に全ファイルを結合)};
    D --> E{結合テキストを行ごとに処理};
    E --> F{タグ定義行か？\n(正規表現)};
    F -- Yes --> G{タグ名(JP/EN), アイコン, 説明抽出\n(正規表現)};
    G --> H{次の行はメタ情報か？\n(正規表現)};
    H -- Yes --> I{メタ情報抽出};
    I --> H;
    H -- No --> J{タグ情報を辞書に格納};
    J --> E;
    F -- No --> E;
    E --> K{全行処理完了};
    K --> L{タグデータリストをJSONに変換};
    L --> M{JSONファイル出力\n(jp_tags.json)};
    M --> N[終了];
```

## 考慮事項

*   `[[include ...]]` の処理は、ファイルパスの解決と再帰的な読み込みを正確に行う必要があります。
*   正規表現は、アイコンや英語タグ名の有無に対応できるように設計する必要があります。
*   Wikidotの他の構文（CSSモジュール、タブビューなど）は無視します。

## 出力ファイル

*   `jp_tags.json`